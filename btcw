imporiimport tensorflow as tf
tf.config.run_functions_eagerly(True)
tf.data.experimental.enable_debug_mode()
import ccxt
import ta
import time
import pytz
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from binance.client import Client
from binance.enums import *
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional
from datetime import datetime
from tqdm import tqdm
from tensorflow.keras.layers import Flatten
from ta.momentum import RSIIndicator
from datetime import datetime, timedelta
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.optimizers import Adam
from matplotlib.dates import DateFormatter
from keras.layers import GRU
import matplotlib.pyplot as plt




# Definição dos parâmetros
PAIR = 'BTC/USDT'
BATCH_SIZE = 25
EPOCHS = 30
INTERVAL = '1h'  # intervalo de 1 HORA
LSTM_WINDOW = 60 # janela de 60 dias para a LSTM
LIMIT = 1000  # limite de 1000 barras (máximo permitido)
input_dim = 7
data_range = timedelta(days=180)

# Define o fuso horário para o horário de Brasília
brasil_tz = pytz.timezone('America/Sao_Paulo')


# Configurações
exchange_name = 'coinbasepro'  # Use 'binance', 'kraken', 'coinbasepro', etc.
pair = 'BTC/USDT'  # Par de moedas
interval = '1h'  # Intervalo das velas

# Criando a conexão com a exchange
exchange = getattr(ccxt, exchange_name)()

# Converte as datas para timestamp em milissegundos
# Define o período de busca dos dados
fim_dt = datetime.now()
inicio_dt = fim_dt - data_range

# Converte as datas para timestamp em milissegundos
inicio_ts = int(inicio_dt.timestamp() * 1000)
fim_ts = int(fim_dt.timestamp() * 1000)

# Cria uma lista vazia para armazenar todos os dados
all_data = []

# Calcula a diferença em horas
total_hours = int((fim_dt - inicio_dt).total_seconds() / 3600)


print ("BUSCANDO DADOS BTC-USD ...")

# Inicializa a barra de progresso
pbar = tqdm(total=total_hours)



while inicio_ts < fim_ts:

    # Busca os dados
    data = exchange.fetch_ohlcv(pair, interval, since=inicio_ts)

    # Se não retornar dados, sai do loop
    if not data:
        break

    # Adiciona os dados à nossa lista
    all_data += data

    # Atualiza o timestamp de início para o timestamp da última vela + intervalo
    inicio_ts = data[-1][0] + 1

    # Atualiza a barra de progresso
    pbar.update(len(data))

    # Pausa para evitar atingir o limite de requisições da API
    time.sleep(exchange.rateLimit / 1000)

pbar.close()


print("Número total de velas coletadas: ", len(all_data))

klines=all_data


df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
df['timestamp'] = df['timestamp'].dt.tz_localize('UTC').dt.tz_convert(brasil_tz)
df['open'] = pd.to_numeric(df['open'])
df['high'] = pd.to_numeric(df['high'])
df['low'] = pd.to_numeric(df['low'])
df['close'] = pd.to_numeric(df['close'])
df['volume'] = pd.to_numeric(df['volume'])
df = df[['timestamp', 'open', 'high', 'low', 'close','volume']]




print(df.head())
df_original = df.copy()


# Seleciona apenas as colunas relevantes e converte em um array NumPy
#data = df[['close']].to_numpy()

# Calcular o indicador técnico RSI
rsi_indicator = RSIIndicator(close = df['close'], window = 14)
df['RSI'] = rsi_indicator.rsi()

macd_indicator = ta.trend.MACD(df['close'], window_slow=26, window_fast=12, window_sign=9)
df['MACD'] = macd_indicator.macd()

# Calcule o OBV
df['obv'] = ta.volume.on_balance_volume(df['close'], df['volume'])

# Remove os valores NaN do DataFrame
df = df.dropna().reset_index(drop=True)

# Excluir as primeiras linhas que não têm RSI calculadodf = df.dropna().reset_index(drop=True)
print("Número de pontos de dados após remover NaNs: ", len(df))


# Crie um novo scaler para a coluna 'close'
scaler_close = MinMaxScaler()
df[['close']] = scaler_close.fit_transform(df[['close']].values)

# Crie um novo scaler para a coluna 'RSI'
scaler_rsi = MinMaxScaler()
df[['RSI']] = scaler_rsi.fit_transform(df[['RSI']].values)

# Cria um novo scaler para a coluna 'MACD'
scaler_macd = MinMaxScaler()
df[['MACD']] = scaler_macd.fit_transform(df[['MACD']].values)

# Incluir 'high', 'low' e 'open' na normalização
scaler_open = MinMaxScaler()
scaler_high = MinMaxScaler()
scaler_low = MinMaxScaler()

df[['open']] = scaler_open.fit_transform(df[['open']].values)
df[['high']] = scaler_high.fit_transform(df[['high']].values)
df[['low']] = scaler_low.fit_transform(df[['low']].values)


# Cria um novo scaler para a coluna 'OBV'
scaler_obv = MinMaxScaler()
df[['obv']] = scaler_obv.fit_transform(df[['obv']].values)

# Remova a coluna 'volume'
df = df.drop('volume', axis=1)

data = df[['open', 'high', 'low', 'close', 'RSI', 'MACD', 'obv']].to_numpy()

print(df.head())

def create_sequences(data, window):
    xs = []
    ys = []

    for i in range(window, len(data)):
        xs.append(data[i-window:i])
        ys.append(data[i, 0])  # seleciona apenas o preço de fechamento como alvo

    return np.array(xs), np.array(ys)

# Calcula a quantidade de dias para a previsão
dias_prev = 1


# Calcula o índice onde os dados de treinamento devem terminar e os dados de teste devem começar
train_size = int(len(data) * 0.8)
test_size = len(data) - train_size

# Divide os dados em conjuntos de treinamento e teste
train_data = data[:train_size]
test_data = data[train_size:] # subtraímos LSTM_WINDOW para ter uma sequência completa para o primeiro ponto de teste

# Cria as sequências de treinamento e teste
x_train, y_train = create_sequences(train_data, LSTM_WINDOW)
x_test, y_test = create_sequences(test_data, LSTM_WINDOW)

# Redimensiona os arrays para terem a forma correta para a LSTM
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 7))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 7))


# Cria modelo GRU
learning_rate = 0.001
num_units = 128
num_layers = 3
activation = 'tanh'
optimizer = 'Adam'


model = Sequential()
model.add(GRU(units=num_units, return_sequences=True, activation=activation, input_shape=(LSTM_WINDOW, input_dim)))
model.add(BatchNormalization())
model.add(Dropout(0.1))
for i in range(num_layers-1):
    model.add(GRU(units=num_units, return_sequences=True, activation=activation))
    model.add(BatchNormalization())
    model.add(Dropout(0.1))
model.add(GRU(units=num_units, activation=activation))
model.add(Dropout(0.1))
model.add(Dense(units=1, activation=activation))

optimizer = Adam(lr=learning_rate)




# Cria o modelo LSTM bidirecional
#model = Sequential() 
#model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(LSTM_WINDOW, input_dim))) 
#model.add(Bidirectional(LSTM(units=64, return_sequences=True))) 
#model.add(BatchNormalization()) 
#model.add(Dropout(0.1)) 
#model.add(Bidirectional(LSTM(units=32))) 
#model.add(Dropout(0.1)) 
#model.add(Dense(1)) 
#model.add(Dense(1, activation='relu'))
#model.add(Dense(units=1, activation='linear'))
    




model.summary()

print("TREINANDO A REDE NEURAL ...")


# Adiciona os callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=2)

# Compila e treina o modelo com EarlyStopping
model.compile(optimizer=Adam(learning_rate), loss='mean_squared_error')
history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test), verbose=1,callbacks=[early_stop] )

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()


print ("CALCULANDO AS PREVISOES PARA O PROXIMO DIA...")

# Faz a previsão dos valores do par de negociação para os próximos dias_prev dias
# Faz a previsão dos valores do par de negociação para os próximos dias_prev dias
predicted_values = []

# atualiza last_sequence
last_sequence = x_test[-1]

for i in range(dias_prev * 24):  # prevendo os próximos "dias_prev" dias, hora a hora
    predicted_value = model.predict(np.array([last_sequence]))
    predicted_values.append(predicted_value[0][0])
    last_sequence = np.roll(last_sequence, -1, axis=0)
    last_sequence[-1, 3] = predicted_value[0][0]  # Atualiza o valor de 'close' na sequência com o último valor previsto

    if i >= len(y_test):
        last_sequence[-1, 3] = predicted_value[0][0]  # Usa o último valor previsto para datas futuras
    else:
        last_sequence[-1, 3] = y_test[i]  # Insere o valor real no lugar do valor previsto para datas futuras


# Reverte a normalização
predicted_values = np.array(predicted_values).reshape(-1, 1)
predicted_values = scaler_close.inverse_transform(predicted_values)
y_test = y_test.reshape(-1, 1)
y_test = scaler_close.inverse_transform(y_test)

# Cria uma lista com as datas correspondentes à previsão
prev_dates = pd.date_range(start=df_original['timestamp'].iloc[-1] + timedelta(hours=1), periods=dias_prev * 24, freq='H').tolist()

# Cria um DataFrame para exibir os valores previstos e os valores reais dos últimos dias
print(f"Tamanho dos arrays - previsto: {len(predicted_values)} / real: {len(y_test)}")
df_prev = pd.DataFrame({'timestamp': prev_dates, 'Valor Previsto': predicted_values.ravel()})

# Cria o gráfico
fig, ax = plt.subplots(figsize=(12, 8))

# Plot dos valores de 'close' da amostragem
ax.plot(df_original['timestamp'], df_original['close'], color='blue')
ax.plot(df_prev['timestamp'], df_prev['Valor Previsto'], linestyle='--', color='red')

# Configurações do gráfico
ax.set_ylabel('Preço')
ax.set_title('Previsão do preço do par de negociação')

# Define o intervalo do eixo x para mostrar apenas as últimas 24 horas
last_24_hours = pd.date_range(end=df_prev['timestamp'].iloc[-1], periods=24, freq='H')
ax.set_xlim(last_24_hours[0], last_24_hours[-1])

# Encontre o valor máximo e mínimo e seus respectivos índices
max_value = df_prev['Valor Previsto'].max()
max_idx = df_prev['Valor Previsto'].idxmax()
min_value = df_prev['Valor Previsto'].min()
min_idx = df_prev['Valor Previsto'].idxmin()

# Anote o valor máximo e mínimo no gráfico
ax.annotate('Max: {:.2f}'.format(max_value), xy=(df_prev['timestamp'][max_idx], max_value), 
            xytext=(df_prev['timestamp'][max_idx], max_value+5),
            arrowprops=dict(facecolor='green', shrink=0.05))
ax.annotate('Min: {:.2f}'.format(min_value), xy=(df_prev['timestamp'][min_idx], min_value), 
            xytext=(df_prev['timestamp'][min_idx], min_value-5),
            arrowprops=dict(facecolor='red', shrink=0.05))

# Define o intervalo do eixo y para começar 25% abaixo do valor mínimo e terminar 25% acima do valor máximo
y_min = min_value - 0.25 * (max_value - min_value)
y_max = max_value + 0.25 * (max_value - min_value)
ax.set_ylim(y_min, y_max)

# Mostra o gráfico
plt.show()


# Imprime os valores previstos para as próximas 24 horas
print("Valores previstos para as próximas 24 horas:")
print(df_prev.tail(24).to_string(index=False))mport tensorflow as tf
tf.config.run_functions_eagerly(True)
tf.data.experimental.enable_debug_mode()
import ccxt
import ta
import time
import pytz
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from binance.client import Client
from binance.enums import *
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional
from datetime import datetime
from tqdm import tqdm
from tensorflow.keras.layers import Flatten
from ta.momentum import RSIIndicator
from datetime import datetime, timedelta
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.optimizers import Adam
from matplotlib.dates import DateFormatter
from keras.layers import GRU
import matplotlib.pyplot as plt
from keras.callbacks import ModelCheckpoint, TensorBoard
import time


# Definição dos parâmetros
PAIR = 'BTC/USDT'
BATCH_SIZE = 25
EPOCHS = 30
INTERVAL = '1h'  # intervalo de 1 HORA
LSTM_WINDOW = 60 # janela de 60 dias para a LSTM
LIMIT = 1000  # limite de 1000 barras (máximo permitido)
input_dim = 7
data_range = timedelta(days=182)

# Define o fuso horário para o horário de Brasília
brasil_tz = pytz.timezone('America/Sao_Paulo')


# Configurações
exchange_name = 'coinbasepro'  # Use 'binance', 'kraken', 'coinbasepro', etc.
pair = 'BTC/USDT'  # Par de moedas
interval = '1h'  # Intervalo das velas

# Criando a conexão com a exchange
exchange = getattr(ccxt, exchange_name)()

# Converte as datas para timestamp em milissegundos
# Define o período de busca dos dados
fim_dt = datetime.now()
inicio_dt = fim_dt - data_range

# Converte as datas para timestamp em milissegundos
inicio_ts = int(inicio_dt.timestamp() * 1000)
fim_ts = int(fim_dt.timestamp() * 1000)

# Cria uma lista vazia para armazenar todos os dados
all_data = []

# Calcula a diferença em horas
total_hours = int((fim_dt - inicio_dt).total_seconds() / 3600)


print ("BUSCANDO DADOS BTC-USD ...")

# Inicializa a barra de progresso
pbar = tqdm(total=total_hours)



while inicio_ts < fim_ts:

    # Busca os dados
    data = exchange.fetch_ohlcv(pair, interval, since=inicio_ts)

    # Se não retornar dados, sai do loop
    if not data:
        break

    # Adiciona os dados à nossa lista
    all_data += data

    # Atualiza o timestamp de início para o timestamp da última vela + intervalo
    inicio_ts = data[-1][0] + 1

    # Atualiza a barra de progresso
    pbar.update(len(data))

    # Pausa para evitar atingir o limite de requisições da API
    time.sleep(exchange.rateLimit / 1000)

pbar.close()


print("Número total de velas coletadas: ", len(all_data))

klines=all_data


df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
df['timestamp'] = df['timestamp'].dt.tz_localize('UTC').dt.tz_convert(brasil_tz)
df['open'] = pd.to_numeric(df['open'])
df['high'] = pd.to_numeric(df['high'])
df['low'] = pd.to_numeric(df['low'])
df['close'] = pd.to_numeric(df['close'])
df['volume'] = pd.to_numeric(df['volume'])
df = df[['timestamp', 'open', 'high', 'low', 'close','volume']]




print(df.head())
df_original = df.copy()


# Seleciona apenas as colunas relevantes e converte em um array NumPy
#data = df[['close']].to_numpy()

# Calcular o indicador técnico RSI
rsi_indicator = RSIIndicator(close = df['close'], window = 14)
df['RSI'] = rsi_indicator.rsi()

macd_indicator = ta.trend.MACD(df['close'], window_slow=26, window_fast=12, window_sign=9)
df['MACD'] = macd_indicator.macd()

# Calcule o OBV
df['obv'] = ta.volume.on_balance_volume(df['close'], df['volume'])

# Remove os valores NaN do DataFrame
df = df.dropna().reset_index(drop=True)

# Excluir as primeiras linhas que não têm RSI calculadodf = df.dropna().reset_index(drop=True)
print("Número de pontos de dados após remover NaNs: ", len(df))


# Crie um novo scaler para a coluna 'close'
scaler_close = MinMaxScaler()
df[['close']] = scaler_close.fit_transform(df[['close']].values)

# Crie um novo scaler para a coluna 'RSI'
scaler_rsi = MinMaxScaler()
df[['RSI']] = scaler_rsi.fit_transform(df[['RSI']].values)

# Cria um novo scaler para a coluna 'MACD'
scaler_macd = MinMaxScaler()
df[['MACD']] = scaler_macd.fit_transform(df[['MACD']].values)

# Incluir 'high', 'low' e 'open' na normalização
scaler_open = MinMaxScaler()
scaler_high = MinMaxScaler()
scaler_low = MinMaxScaler()

df[['open']] = scaler_open.fit_transform(df[['open']].values)
df[['high']] = scaler_high.fit_transform(df[['high']].values)
df[['low']] = scaler_low.fit_transform(df[['low']].values)


# Cria um novo scaler para a coluna 'OBV'
scaler_obv = MinMaxScaler()
df[['obv']] = scaler_obv.fit_transform(df[['obv']].values)

# Remova a coluna 'volume'
df = df.drop('volume', axis=1)

data = df[['open', 'high', 'low', 'close', 'RSI', 'MACD', 'obv']].to_numpy()

print(df.head())

def create_sequences(data, window):
    xs = []
    ys = []

    for i in range(window, len(data)):
        xs.append(data[i-window:i])
        ys.append(data[i, 0])  # seleciona apenas o preço de fechamento como alvo

    return np.array(xs), np.array(ys)

# Calcula a quantidade de dias para a previsão
dias_prev = 1


# Calcula o índice onde os dados de treinamento devem terminar e os dados de teste devem começar
train_size = int(len(data) * 0.8)
test_size = len(data) - train_size

# Divide os dados em conjuntos de treinamento e teste
train_data = data[:train_size]
test_data = data[train_size:] # subtraímos LSTM_WINDOW para ter uma sequência completa para o primeiro ponto de teste

# Cria as sequências de treinamento e teste
x_train, y_train = create_sequences(train_data, LSTM_WINDOW)
x_test, y_test = create_sequences(test_data, LSTM_WINDOW)

# Redimensiona os arrays para terem a forma correta para a LSTM
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 7))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 7))


# Cria modelo GRU
learning_rate = 0.0001
num_units = 128
num_layers = 3
activation = 'tanh'
optimizer = 'Adam'


model = Sequential()
model.add(GRU(units=num_units, return_sequences=True, activation=activation, input_shape=(LSTM_WINDOW, input_dim)))
model.add(BatchNormalization())
model.add(Dropout(0.1))
for i in range(num_layers-1):
    model.add(GRU(units=num_units, return_sequences=True, activation=activation))
    model.add(BatchNormalization())
    model.add(Dropout(0.1))
model.add(GRU(units=num_units, activation=activation))
model.add(Dropout(0.1))
model.add(Dense(units=1, activation=activation))

optimizer = Adam(lr=learning_rate)




# Cria o modelo LSTM bidirecional
#model = Sequential() 
#model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(LSTM_WINDOW, input_dim))) 
#model.add(Bidirectional(LSTM(units=64, return_sequences=True))) 
#model.add(BatchNormalization()) 
#model.add(Dropout(0.1)) 
#model.add(Bidirectional(LSTM(units=32))) 
#model.add(Dropout(0.1)) 
#model.add(Dense(1)) 
#model.add(Dense(1, activation='relu'))
#model.add(Dense(units=1, activation='linear'))
    




model.summary()

print("TREINANDO A REDE NEURAL ...")


# Adiciona os callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=2)

# Compila e treina o modelo com EarlyStopping
model.compile(optimizer=Adam(learning_rate), loss='mean_squared_error')
history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test), verbose=1,callbacks=[early_stop] )

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()


print ("CALCULANDO AS PREVISOES PARA O PROXIMO DIA...")

# Faz a previsão dos valores do par de negociação para os próximos dias_prev dias
# Faz a previsão dos valores do par de negociação para os próximos dias_prev dias
predicted_values = []

# atualiza last_sequence
last_sequence = x_test[-1]

for i in range(dias_prev * 24):  # prevendo os próximos "dias_prev" dias, hora a hora
    predicted_value = model.predict(np.array([last_sequence]))
    predicted_values.append(predicted_value[0][0])
    last_sequence = np.roll(last_sequence, -1, axis=0)
    last_sequence[-1, 3] = predicted_value[0][0]  # Atualiza o valor de 'close' na sequência com o último valor previsto

    if i >= len(y_test):
        last_sequence[-1, 3] = predicted_value[0][0]  # Usa o último valor previsto para datas futuras
    else:
        last_sequence[-1, 3] = y_test[i]  # Insere o valor real no lugar do valor previsto para datas futuras


# Reverte a normalização
predicted_values = np.array(predicted_values).reshape(-1, 1)
predicted_values = scaler_close.inverse_transform(predicted_values)
y_test = y_test.reshape(-1, 1)
y_test = scaler_close.inverse_transform(y_test)

# Cria uma lista com as datas correspondentes à previsão
prev_dates = pd.date_range(start=df_original['timestamp'].iloc[-1] + timedelta(hours=1), periods=dias_prev * 24, freq='H').tolist()

# Cria um DataFrame para exibir os valores previstos e os valores reais dos últimos dias
print(f"Tamanho dos arrays - previsto: {len(predicted_values)} / real: {len(y_test)}")
df_prev = pd.DataFrame({'timestamp': prev_dates, 'Valor Previsto': predicted_values.ravel()})

# Cria o gráfico
fig, ax = plt.subplots(figsize=(12, 8))

# Plot dos valores de 'close' da amostragem
ax.plot(df_original['timestamp'], df_original['close'], color='blue')
ax.plot(df_prev['timestamp'], df_prev['Valor Previsto'], linestyle='--', color='red')

# Configurações do gráfico
ax.set_ylabel('Preço')
ax.set_title('Previsão do preço do par de negociação')

# Define o intervalo do eixo x para mostrar apenas as últimas 24 horas
last_24_hours = pd.date_range(end=df_prev['timestamp'].iloc[-1], periods=24, freq='H')
ax.set_xlim(last_24_hours[0], last_24_hours[-1])

# Encontre o valor máximo e mínimo e seus respectivos índices
max_value = df_prev['Valor Previsto'].max()
max_idx = df_prev['Valor Previsto'].idxmax()
min_value = df_prev['Valor Previsto'].min()
min_idx = df_prev['Valor Previsto'].idxmin()

# Anote o valor máximo e mínimo no gráfico
ax.annotate('Max: {:.2f}'.format(max_value), xy=(df_prev['timestamp'][max_idx], max_value), 
            xytext=(df_prev['timestamp'][max_idx], max_value+5),
            arrowprops=dict(facecolor='green', shrink=0.05))
ax.annotate('Min: {:.2f}'.format(min_value), xy=(df_prev['timestamp'][min_idx], min_value), 
            xytext=(df_prev['timestamp'][min_idx], min_value-5),
            arrowprops=dict(facecolor='red', shrink=0.05))

# Define o intervalo do eixo y para começar 25% abaixo do valor mínimo e terminar 25% acima do valor máximo
y_min = min_value - 0.25 * (max_value - min_value)
y_max = max_value + 0.25 * (max_value - min_value)
ax.set_ylim(y_min, y_max)

# Mostra o gráfico
plt.show()


# Imprime os valores previstos para as próximas 24 horas
print("Valores previstos para as próximas 24 horas:")
print(df_prev.tail(24).to_string(index=False))t tensorflow as tf
tf.config.run_functions_eagerly(True)
tf.data.experimental.enable_debug_mode()
import ccxt
import ta
import time
import pytz
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from binance.client import Client
from binance.enums import *
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional
from datetime import datetime
from tqdm import tqdm
from tensorflow.keras.layers import Flatten
from ta.momentum import RSIIndicator
from datetime import datetime, timedelta
from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.optimizers import Adam
from matplotlib.dates import DateFormatter


# Definição dos parâmetros
PAIR = 'BTC/USDT'
BATCH_SIZE = 32
EPOCHS = 20
INTERVAL = '1h'  # intervalo de 1 HORA
LSTM_WINDOW = 60 # janela de 60 dias para a LSTM
LIMIT = 1000  # limite de 1000 barras (máximo permitido)
input_dim = 6
data_range = timedelta(days=182)

# Define o fuso horário para o horário de Brasília
brasil_tz = pytz.timezone('America/Sao_Paulo')


# Configurações
exchange_name = 'coinbasepro'  # Use 'binance', 'kraken', 'coinbasepro', etc.
pair = 'BTC/USDT'  # Par de moedas
interval = '1h'  # Intervalo das velas

# Criando a conexão com a exchange
exchange = getattr(ccxt, exchange_name)()

# Converte as datas para timestamp em milissegundos
# Define o período de busca dos dados
fim_dt = datetime.now()
inicio_dt = fim_dt - data_range

# Converte as datas para timestamp em milissegundos
inicio_ts = int(inicio_dt.timestamp() * 1000)
fim_ts = int(fim_dt.timestamp() * 1000)

# Cria uma lista vazia para armazenar todos os dados
all_data = []

# Calcula a diferença em horas
total_hours = int((fim_dt - inicio_dt).total_seconds() / 3600)


print ("BUSCANDO DADOS BTC-USD ...")

# Inicializa a barra de progresso
pbar = tqdm(total=total_hours)



while inicio_ts < fim_ts:

    # Busca os dados
    data = exchange.fetch_ohlcv(pair, interval, since=inicio_ts)

    # Se não retornar dados, sai do loop
    if not data:
        break

    # Adiciona os dados à nossa lista
    all_data += data

    # Atualiza o timestamp de início para o timestamp da última vela + intervalo
    inicio_ts = data[-1][0] + 1

    # Atualiza a barra de progresso
    pbar.update(len(data))

    # Pausa para evitar atingir o limite de requisições da API
    time.sleep(exchange.rateLimit / 1000)

pbar.close()


print("Número total de velas coletadas: ", len(all_data))

klines=all_data


df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
df['timestamp'] = df['timestamp'].dt.tz_localize('UTC').dt.tz_convert(brasil_tz)
df['open'] = pd.to_numeric(df['open'])
df['high'] = pd.to_numeric(df['high'])
df['low'] = pd.to_numeric(df['low'])
df['close'] = pd.to_numeric(df['close'])
df = df[['timestamp', 'open', 'high', 'low', 'close']]



print(df.head())
df_original = df.copy()


# Seleciona apenas as colunas relevantes e converte em um array NumPy
#data = df[['close']].to_numpy()

# Calcular o indicador técnico RSI
rsi_indicator = RSIIndicator(close = df['close'], window = 14)
df['RSI'] = rsi_indicator.rsi()

macd_indicator = ta.trend.MACD(df['close'], window_slow=26, window_fast=12, window_sign=9)
df['MACD'] = macd_indicator.macd()

# Remove os valores NaN do DataFrame
df = df.dropna().reset_index(drop=True)

# Excluir as primeiras linhas que não têm RSI calculadodf = df.dropna().reset_index(drop=True)
print("Número de pontos de dados após remover NaNs: ", len(df))


# Crie um novo scaler para a coluna 'close'
scaler_close = MinMaxScaler()
df[['close']] = scaler_close.fit_transform(df[['close']].values)

# Crie um novo scaler para a coluna 'RSI'
scaler_rsi = MinMaxScaler()
df[['RSI']] = scaler_rsi.fit_transform(df[['RSI']].values)

# Cria um novo scaler para a coluna 'MACD'
scaler_macd = MinMaxScaler()
df[['MACD']] = scaler_macd.fit_transform(df[['MACD']].values)

# Incluir 'high', 'low' e 'open' na normalização
scaler_open = MinMaxScaler()
scaler_high = MinMaxScaler()
scaler_low = MinMaxScaler()

df[['open']] = scaler_open.fit_transform(df[['open']].values)
df[['high']] = scaler_high.fit_transform(df[['high']].values)
df[['low']] = scaler_low.fit_transform(df[['low']].values)


data = df[['open', 'high', 'low', 'close', 'RSI', 'MACD']].to_numpy()

print(df.head())

def create_sequences(data, window):
    xs = []
    ys = []

    for i in range(window, len(data)):
        xs.append(data[i-window:i])
        ys.append(data[i, 0])  # seleciona apenas o preço de fechamento como alvo

    return np.array(xs), np.array(ys)

# Calcula a quantidade de dias para a previsão
dias_prev = 1


# Calcula o índice onde os dados de treinamento devem terminar e os dados de teste devem começar
train_size = int(len(data) * 0.8)
test_size = len(data) - train_size

# Divide os dados em conjuntos de treinamento e teste
train_data = data[:train_size]
test_data = data[train_size:] # subtraímos LSTM_WINDOW para ter uma sequência completa para o primeiro ponto de teste

# Cria as sequências de treinamento e teste
x_train, y_train = create_sequences(train_data, LSTM_WINDOW)
x_test, y_test = create_sequences(test_data, LSTM_WINDOW)

# Redimensiona os arrays para terem a forma correta para a LSTM
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 6))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 6))

# Cria o modelo LSTM bidirecional
model = Sequential()
model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(LSTM_WINDOW, input_dim)))
model.add(Bidirectional(LSTM(units=64, return_sequences=True)))
model.add(BatchNormalization())
model.add(Dropout(0.1))
model.add(Bidirectional(LSTM(units=32)))
model.add(Dropout(0.1))
model.add(Dense(1))
#model.add(Dense(1, activation='relu'))



model.summary()

print("TREINANDO A REDE NEURAL BI-LSTM...")

# Cria um objeto EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=4)

# Compila e treina o modelo com EarlyStopping
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')
model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(x_test, y_test), callbacks=[early_stop])

print ("CALCULANDO AS PREVISOES PARA O PROXIMO DIA...")

# Faz a previsão dos valores do par de negociação para os próximos dias_prev dias
# Faz a previsão dos valores do par de negociação para os próximos dias_prev dias
predicted_values = []

# atualiza last_sequence
last_sequence = x_test[-1]

for i in range(dias_prev * 24):  # prevendo os próximos "dias_prev" dias, hora a hora
    predicted_value = model.predict(np.array([last_sequence]))
    predicted_values.append(predicted_value[0][0])
    last_sequence = np.roll(last_sequence, -1, axis=0)
    last_sequence[-1, 3] = predicted_value[0][0]  # Atualiza o valor de 'close' na sequência com o último valor previsto

    if i >= len(y_test):
        last_sequence[-1, 3] = predicted_value[0][0]  # Usa o último valor previsto para datas futuras
    else:
        last_sequence[-1, 3] = y_test[i]  # Insere o valor real no lugar do valor previsto para datas futuras


# Reverte a normalização
predicted_values = np.array(predicted_values).reshape(-1, 1)
predicted_values = scaler_close.inverse_transform(predicted_values)
y_test = y_test.reshape(-1, 1)
y_test = scaler_close.inverse_transform(y_test)

# Cria uma lista com as datas correspondentes à previsão
prev_dates = pd.date_range(start=df_original['timestamp'].iloc[-1] + timedelta(hours=1), periods=dias_prev * 24, freq='H').tolist()

# Cria um DataFrame para exibir os valores previstos e os valores reais dos últimos dias
print(f"Tamanho dos arrays - previsto: {len(predicted_values)} / real: {len(y_test)}")
df_prev = pd.DataFrame({'timestamp': prev_dates, 'Valor Previsto': predicted_values.ravel()})

# Cria o gráfico
fig, ax = plt.subplots(figsize=(12, 8))

# Plot dos valores de 'close' da amostragem
ax.plot(df_original['timestamp'], df_original['close'], color='blue')
ax.plot(df_prev['timestamp'], df_prev['Valor Previsto'], linestyle='--', color='red')

# Configurações do gráfico
ax.set_ylabel('Preço')
ax.set_title('Previsão do preço do par de negociação')

# Define o intervalo do eixo x para mostrar apenas as últimas 24 horas
last_24_hours = pd.date_range(end=df_prev['timestamp'].iloc[-1], periods=24, freq='H')
ax.set_xlim(last_24_hours[0], last_24_hours[-1])

# Encontre o valor máximo e mínimo e seus respectivos índices
max_value = df_prev['Valor Previsto'].max()
max_idx = df_prev['Valor Previsto'].idxmax()
min_value = df_prev['Valor Previsto'].min()
min_idx = df_prev['Valor Previsto'].idxmin()

# Anote o valor máximo e mínimo no gráfico
ax.annotate('Max: {:.2f}'.format(max_value), xy=(df_prev['timestamp'][max_idx], max_value), 
            xytext=(df_prev['timestamp'][max_idx], max_value+5),
            arrowprops=dict(facecolor='green', shrink=0.05))
ax.annotate('Min: {:.2f}'.format(min_value), xy=(df_prev['timestamp'][min_idx], min_value), 
            xytext=(df_prev['timestamp'][min_idx], min_value-5),
            arrowprops=dict(facecolor='red', shrink=0.05))

# Mostra o gráfico
plt.show()

# Imprime os valores previstos para as próximas 24 horas
print("Valores previstos para as próximas 24 horas:")
print(df_prev.tail(24).to_string(index=False))
