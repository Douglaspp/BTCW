#@title
# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import ta
import ccxt
from tensorflow.keras.callbacks import Callback
from tqdm.keras import TqdmCallback
from binance.client import Client
from binance.enums import *
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional
from datetime import datetime
#from tqdm import tqdm
import tensorflow as tf
import gym
from stable_baselines3.common.callbacks import BaseCallback
from gym import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from tqdm.notebook import tqdm
from keras.layers import Reshape
from keras.layers import Activation




tf.config.run_functions_eagerly(True)
tf.data.experimental.enable_debug_mode()


# Defini��o dos par�metros
API_KEY = 'hruZgjj2PS9WCvNrT3scR726HlMLc0vnWWkLceUigMdbJECG2ay331Euh4qeDSjM'
SECRET_KEY = 'ZReFgghppeiV6qQFwojT5EczFGjANLGOzkL7Q35j5P8hGopILGDnfY3queFSXfFO'
PAIR = 'BTCUSDT'
BATCH_SIZE = 32
EPOCHS = 10
INTERVAL = Client.KLINE_INTERVAL_1HOUR  # intervalo de 1 HORA
LSTM_WINDOW = 10 # janela de 60 dias para a LSTM
x_train = []
y_train = []

class TqdmRLCallback(BaseCallback):
    def __init__(self, tqdm_object):
        super(TqdmRLCallback, self).__init__()
        self.tqdm_object = tqdm_object

    def _on_step(self) -> bool:
        self.tqdm_object.update(1)
        return True

class TqdmKerasCallback(Callback):
    def on_train_begin(self, logs=None):
        self.epochs = self.params['epochs']
        self.steps = self.params['steps']
        self.epoch_progress_bar = tqdm(total=self.epochs, desc="Epochs", position=0)
    
    def on_epoch_end(self, epoch, logs=None):
        self.epoch_progress_bar.update(1)
        
    def on_train_end(self, logs=None):
        self.epoch_progress_bar.close()

class TradingEnv(gym.Env):
    def __init__(self, data):
        super(TradingEnv, self).__init__()
        self.data = data
        self.current_step = 0
        self.action_space = spaces.Discrete(3)  # 0: Hold, 1: Buy, 2: Sell
        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(2,), dtype=np.float32)
    def reset(self):
        self.current_step = 0
        return self._next_observation()
    def _next_observation(self):
        return np.array([self.data[self.current_step], self.current_step])
    def step(self, action):
        self.current_step += 1
        current_price = self.data[self.current_step]
        previous_price = self.data[self.current_step - 1]
        reward = 0
        if action == 1:  # Comprar
            reward = previous_price - current_price
        elif action == 2:  # Vender
            reward = current_price - previous_price
        done = self.current_step == len(self.data) - 1
        obs = self._next_observation()
        return obs, reward, done, {}


def generate_all_predictions(model, data, window, scaler):
    
    predictions = []
    for i in range(window, len(data)):
        x = data[i-window:i, :]
        x = np.expand_dims(x, axis=0)
        predicted_value = model.predict(np.expand_dims(x, axis=0))  # Modifique a dimensão de entrada aqui
        predictions.append(predicted_value[0][0])
    predictions = np.array(predictions).reshape(-1, 1)
    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))

    return predictions


def get_coinbase_data(pair, interval, start_date, end_date):
    exchange = ccxt.coinbasepro()
    timeframe = '1h'  # intervalo de 1 hora

    # Ajuste da data de início para incluir 14 dias a mais para calcular o RSI corretamente
    start_date = datetime.strptime(start_date, '%m/%d/%Y') - pd.DateOffset(days=14)
    end_date = datetime.strptime(end_date, '%m/%d/%Y')

    klines = []
    current_date = start_date

    with tqdm(desc="Buscando dados") as pbar:
        while current_date < end_date:
            since = exchange.parse8601(current_date.isoformat())
            limit = 1000
            new_klines = exchange.fetch_ohlcv(pair, timeframe, since, limit)
            klines.extend(new_klines)
            pbar.update(len(new_klines))

            if not new_klines:
                break

            last_kline_timestamp = new_klines[-1][0]
            current_date = datetime.utcfromtimestamp(last_kline_timestamp / 1000) + pd.DateOffset(hours=1)

    # Adicione o RSI aos dados do DataFrame
    df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')

    # Converta a coluna 'timestamp' para timestamps Unix
    df['timestamp'] = pd.to_datetime(df['timestamp']).astype(np.int64) // 10**9

    df['close'] = pd.to_numeric(df['close'])
    df['rsi'] = ta.momentum.RSIIndicator(df['close'], window=14).rsi()

    # Remova as primeiras 14 * 24 linhas de dados (14 dias) antes de retornar o DataFrame
    df = df.iloc[14 * 24:]

    return df



def preprocess_data(df, seq_len, target_column, scale_data=True):
    data = df.copy()

    scaler = None
    if scale_data:
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data[[target_column]])
        data[[target_column]] = scaled_data

    sequence_data = []
    target_data = []

    for i in range(len(data) - seq_len):
        if i + seq_len < len(data):
            sequence_data.append(data.iloc[i:i + seq_len])
            target_data.append(data.iloc[i + seq_len][target_column])  # get only the target column
    print("Shape dos dados após preprocessamento: ", np.array(sequence_data).shape, np.array(target_data).shape)

    train_data = df.copy()
    train_data = train_data.iloc[:int(0.8 * len(train_data)), :].values
    train_data = train_data[:, 1:]
    test_data = df.copy()
    test_data = test_data.iloc[int(0.8 * len(test_data)):, :].values
    test_data = test_data[:, 1:]

    return np.array(sequence_data), np.array(target_data), scaler


def create_sequences(df, seq_length):
    if isinstance(df, pd.DataFrame):
        df = df.values  # Convert the DataFrame to a numpy array only if df is a DataFrame
    xs = []
    ys = []

    for i in range(len(df)-seq_length):
        x = df[i:(i+seq_length)]
        y = df[i+seq_length][4]  # 4 é o índice da coluna 'close' nos dados convertidos em numpy array
        xs.append(x)
        ys.append(y)

    return np.array(xs), np.array(ys)








def create_lstm_model(window):
    print("Building LSTM model...")
    model = Sequential()
    model.add(LSTM(64, input_shape=(window, 7)))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))
    model.add(Activation('linear'))

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
  

    def predict_with_scaling(X):
        if scaler is not None:
            X_scaled = scaler.transform(X)
        else:
            X_scaled = X
        y_pred = model.predict(X_scaled)
        if scaler is not None:
            y_pred = scaler.inverse_transform(y_pred)
            
        return y_pred

    model.predict_with_scaling = predict_with_scaling
        
    return model


def predict_values(model, x_test, scaler):
    predicted_values = []
    for i in range(1, len(x_test)):
        x = x_test[i].reshape(1, x_test.shape[1], 2)  # Modifique a dimensão de entrada aqui
        predicted_value = model.predict(x)
        predicted_values.append(predicted_value[0][0])
    predicted_values = np.array(predicted_values).reshape(-1, 1)
    predicted_values = scaler.inverse_transform(predicted_values)
    return predicted_values

def generate_actions(rl_agent, predictions):
    actions = []
    env = TradingEnv(predictions)
    obs = env.reset()
    for _ in range(len(predictions) - 1):
        action, _ = rl_agent.predict(obs)
        actions.append(action)
        obs, _, done, _ = env.step(action)
        if done:
            break
    print("Ações geradas pelo agente de RL: ", actions)
    return np.array(sequence_data), np.array(target_data)



def main():
    inicio = '03/01/2023'#input('Insira a data de inicio para amostragem (mm/dd/yyyy): ')
    fim = '04/01/2023' #input('Insira a data de fim para amostragem (mm/dd/yyyy): ')
    klines = get_coinbase_data('BTC-USDT', INTERVAL, inicio, fim)
    print("Klines", klines.head())
    # Adicione estas duas linhas abaixo
    sequence_length = 20  # Defina o tamanho da sequência que deseja usar
    
    sequence_data, target_data, scaler = preprocess_data(klines, sequence_length, 'close', scale_data=True)
    print("Número de linhas da sequência de dados:", sequence_data.shape[0])
    print("Shape dos dados após preprocessamento: ", sequence_data.shape, target_data.shape)
    

    inicio_prev = '04/01/2023' #input('Insira a data de inicio para previsão (mm/dd/yyyy): ')
    fim_prev ='05/25/2023' #input('Insira a data de fim para previsão (mm/dd/yyyy): ')

    # Calcular o número de dias de previsão com base nas datas inicial e final de previsão
    from datetime import datetime
    inicio_prev_dt =  datetime.strptime(inicio_prev, "%m/%d/%Y")
    fim_prev_dt =  datetime.strptime(fim_prev, "%m/%d/%Y")
    dias_prev = (fim_prev_dt - inicio_prev_dt).days

        # Separação dos dados de treinamento e teste
    data1 = klines.copy()
    train_size = int(0.8 * len(data1))
    train_data = data1[:train_size]
    test_data = data1[train_size:]

    # Definir o tamanho da janela como o número de linhas da sequência de dados
    #LSTM_WINDOW = sequence_data.shape[0]
    print("Tipo de train_data:", type(train_data))

    train_data = train_data.values  # Convert the DataFrame to a numpy array

    # Definindo o ponto de divisão para 80% dos dados
    train_split = int(0.8 * len(train_data))

    x_train, y_train = create_sequences(train_data[:train_split], LSTM_WINDOW)
    x_test, y_test = create_sequences(train_data[train_split:], LSTM_WINDOW)
    print("Dados de entrada do modelo:")
    print("x_train shape:", x_train.shape)
    print("y_train shape:", y_train.shape)
    print("x_train[0]:", x_train[0])
    print("y_train[0]:", y_train[0])
    print("x_test shape:", x_test.shape)
    print("y_test shape:", y_test.shape)
    print("x_test[0]:", x_test[0])
    print("y_test[0]:", y_test[0])

    
    model = create_lstm_model(LSTM_WINDOW)



    print("\nTraining model...")
    print(model.summary())
    print("Treinamento concluído!")



    # Gere previs�es LSTM para todos os pontos no conjunto de treinamento
    train_predictions = generate_all_predictions(model, train_data, LSTM_WINDOW, scaler)
    print(train_predictions.shape)

    # Crie o ambiente de RL com as previs�es LSTM do per�odo de amostragem
    train_env = DummyVecEnv([lambda: TradingEnv(train_predictions)])
    predicted_values = predict_values(model, x_test, scaler)

    # Treine o agente de RL usando o algoritmo PPO
    total_timesteps = 10000
    with tqdm(total=total_timesteps, desc="Treinando o agente RL", unit="steps", leave=False) as pbar:
        rl_agent = PPO('MlpPolicy', train_env, verbose=1)
        callback = TqdmRLCallback(pbar)
        rl_agent.learn(total_timesteps=total_timesteps, callback=callback)

    # Gere a��es de compra e venda para o per�odo de previs�o
    actions = generate_actions(rl_agent, predicted_values.ravel())
    y_test = scaler.inverse_transform(y_test)
    df_pred = pd.DataFrame({'Data': pd.date_range(start=inicio_prev_dt, end=fim_prev_dt, freq='D')[:len(predicted_values)], 'Valor Previsto': predicted_values.ravel()})
    df_real = pd.DataFrame({'Data': pd.date_range(start=inicio_prev_dt, end=fim_prev_dt, freq='D')[:len(y_test)], 'Valor Real': y_test.ravel()})
    df_actions = pd.DataFrame({'Data': pd.date_range(start=inicio_prev_dt, end=fim_prev_dt, freq='D')[:len(actions)], 'Acao': actions})
    df_final = pd.merge(df_pred, df_real, on='Data')
    df_final = pd.merge(df_final, df_actions, on='Data')
    mask = df_real['Data'] >= datetime.now()
    df_final.loc[mask, 'Valor Real'] = np.nan
    action_mapping = {0: "Manter", 1: "Comprar", 2: "Vender"}
    df_final['Acao'] = df_final['Acao'].map(action_mapping)
    print(df_final)

if __name__ == '__main__':
    main()
